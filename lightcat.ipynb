{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mamekin05108/signatecup2024summer/blob/main/lightcat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvcbxY4UzTh3",
        "outputId": "387e50b8-16ad-4724-f282-4199d9de5f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_RmK63MjRXa",
        "outputId": "213f5336-5802-4a89-bf82-20436cd549c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import re\n",
        "import lightgbm as lgb\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "\n",
        "\n",
        "# warningsを非表示にする\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "GPtf2SeBzV9X"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"/content/drive/MyDrive/Signate/2024summer/csv_data/dft_train.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/Signate/2024summer/csv_data/dft_test.csv\")\n",
        "ss = pd.read_csv(\"/content/drive/MyDrive/Signate/2024summer/data/sample_submit.csv\", header=None)"
      ],
      "metadata": {
        "id": "2FTiglD3zYMY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = df_train[target]\n",
        "train_x = df_train.drop(target, axis=1)"
      ],
      "metadata": {
        "id": "jTC1POkYyV0B"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = df_test\n",
        "test_x = test_x.drop(target, axis=1)"
      ],
      "metadata": {
        "id": "hljP6qCBzzBU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# モデル\n"
      ],
      "metadata": {
        "id": "jgjYKucvdM4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_lgb = {\n",
        "    \"n_estimators\": 3000,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"subsample_freq\": 1,\n",
        "    \"subsample\": 0.8,\n",
        "    \"random_seed\": 0,\n",
        "}"
      ],
      "metadata": {
        "id": "iFQCp38z3JpH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_cat = {\n",
        "    \"iterations\": 3000,  # n_estimatorsに相当\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"colsample_bylevel\": 0.8,  # colsample_bytreeに相当\n",
        "    \"random_seed\": 0,\n",
        "    \"verbose\": 100,  # 学習の進捗を100回毎に表示\n",
        "    \"use_best_model\": True,  # 早期停止のための設定\n",
        "}"
      ],
      "metadata": {
        "id": "QWPGZD9WFfzL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_xgb = {\n",
        "    \"n_estimators\": 3000,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"subsample\": 0.8,\n",
        "    \"early_stopping_rounds\": 100,\n",
        "    \"random_state\": 0,\n",
        "}"
      ],
      "metadata": {
        "id": "jv71t_Ba5_e2"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_models = {\n",
        "    'LightGBM': lgb.LGBMClassifier(**params_lgb),\n",
        "    'CatBoost': CatBoostClassifier(**params_cat, early_stopping_rounds=100),\n",
        "    'XGBoost': XGBClassifier(**params_xgb)\n",
        "}"
      ],
      "metadata": {
        "id": "k9EDAzZ4e30L"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WIeiX2sDe26c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_base_models(X, y, models, cols_category, n_splits=5):\n",
        "    meta_features = np.zeros((len(X), len(models)))\n",
        "    oof_predictions = np.zeros(len(X))\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=815)\n",
        "\n",
        "    for i, (model_name, model) in enumerate(models.items()):\n",
        "        print(f\"Training {model_name}...\")\n",
        "        oof_predictions_model = np.zeros(len(X))\n",
        "\n",
        "        for fold, (trn_idx, val_idx) in enumerate(cv.split(X, y), start=1):\n",
        "            trn_x, trn_y = X.iloc[trn_idx], y.iloc[trn_idx]\n",
        "            val_x, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "            if isinstance(model, lgb.LGBMClassifier):\n",
        "                model.fit(\n",
        "                    trn_x, trn_y,\n",
        "                    eval_set=[(val_x, val_y)],\n",
        "                    callbacks=[lgb.early_stopping(100, verbose=False)],\n",
        "                    categorical_feature=cols_category,\n",
        "                )\n",
        "            elif isinstance(model, CatBoostClassifier):\n",
        "                train_pool = Pool(data=trn_x, label=trn_y, cat_features=cols_category)\n",
        "                val_pool = Pool(data=val_x, label=val_y, cat_features=cols_category)\n",
        "                model.fit(train_pool, eval_set=val_pool, verbose=False)\n",
        "            elif isinstance(model, XGBClassifier):\n",
        "                model.fit(\n",
        "                    trn_x, trn_y,\n",
        "                    eval_set=[(val_x, val_y)],\n",
        "                    verbose=False,\n",
        "                )\n",
        "            else:\n",
        "                model.fit(trn_x, trn_y)\n",
        "\n",
        "            oof_predictions_model[val_idx] = model.predict_proba(val_x)[:, 1]\n",
        "\n",
        "            auc = roc_auc_score(val_y, oof_predictions_model[val_idx])\n",
        "            print(f\"  Fold {fold}, AUC: {auc:.4f}\")\n",
        "\n",
        "        meta_features[:, i] = oof_predictions_model\n",
        "        oof_predictions += oof_predictions_model / len(models)\n",
        "\n",
        "        auc = roc_auc_score(y, oof_predictions_model)\n",
        "        print(f\"{model_name} OOF AUC: {auc:.4f}\")\n",
        "\n",
        "    return meta_features, oof_predictions"
      ],
      "metadata": {
        "id": "i1YSzCrxN7sM"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_meta_model(meta_features, y, meta_model, n_splits=5):\n",
        "    oof_predictions = np.zeros(len(y))\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=815)\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(cv.split(meta_features, y), start=1):\n",
        "        trn_x, trn_y = meta_features[trn_idx], y.iloc[trn_idx]\n",
        "        val_x, val_y = meta_features[val_idx], y.iloc[val_idx]\n",
        "\n",
        "        meta_model.fit(trn_x, trn_y)\n",
        "        oof_predictions[val_idx] = meta_model.predict_proba(val_x)[:, 1]\n",
        "\n",
        "        auc = roc_auc_score(val_y, oof_predictions[val_idx])\n",
        "        print(f\"Meta Model Fold {fold}, AUC: {auc:.4f}\")\n",
        "\n",
        "    auc = roc_auc_score(y, oof_predictions)\n",
        "    print(f\"Meta Model OOF AUC: {auc:.4f}\")\n",
        "\n",
        "    return oof_predictions"
      ],
      "metadata": {
        "id": "d7hPGtGqnL8i"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stacking_predict(X, base_models, meta_model):\n",
        "    meta_features = np.column_stack([model.predict_proba(X)[:, 1] for _, model in base_models.items()])\n",
        "    return meta_model.predict_proba(meta_features)[:, 1]"
      ],
      "metadata": {
        "id": "NfAqhCaGxfXU"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ベースモデルの学習とメタ特徴量の生成\n",
        "meta_features, oof_predictions_base = train_base_models(train_x, train_y, base_models, cols_category)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAdBEO3lxquO",
        "outputId": "05a71579-d1e0-4cc9-f0d1-cf7487249280"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LightGBM...\n",
            "[LightGBM] [Info] Number of positive: 397, number of negative: 2394\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000642 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 776\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142243 -> initscore=-1.796785\n",
            "[LightGBM] [Info] Start training from score -1.796785\n",
            "  Fold 1, AUC: 0.8227\n",
            "[LightGBM] [Info] Number of positive: 397, number of negative: 2394\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000549 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 776\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142243 -> initscore=-1.796785\n",
            "[LightGBM] [Info] Start training from score -1.796785\n",
            "  Fold 2, AUC: 0.8373\n",
            "[LightGBM] [Info] Number of positive: 398, number of negative: 2393\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000519 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 776\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142601 -> initscore=-1.793851\n",
            "[LightGBM] [Info] Start training from score -1.793851\n",
            "  Fold 3, AUC: 0.8349\n",
            "[LightGBM] [Info] Number of positive: 398, number of negative: 2393\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000725 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 776\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142601 -> initscore=-1.793851\n",
            "[LightGBM] [Info] Start training from score -1.793851\n",
            "  Fold 4, AUC: 0.8259\n",
            "[LightGBM] [Info] Number of positive: 398, number of negative: 2394\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000523 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 776\n",
            "[LightGBM] [Info] Number of data points in the train set: 2792, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142550 -> initscore=-1.794269\n",
            "[LightGBM] [Info] Start training from score -1.794269\n",
            "  Fold 5, AUC: 0.8408\n",
            "LightGBM OOF AUC: 0.8315\n",
            "Training CatBoost...\n",
            "  Fold 1, AUC: 0.8176\n",
            "  Fold 2, AUC: 0.8455\n",
            "  Fold 3, AUC: 0.8425\n",
            "  Fold 4, AUC: 0.8172\n",
            "  Fold 5, AUC: 0.8560\n",
            "CatBoost OOF AUC: 0.8351\n",
            "Training XGBoost...\n",
            "  Fold 1, AUC: 0.7979\n",
            "  Fold 2, AUC: 0.8052\n",
            "  Fold 3, AUC: 0.8211\n",
            "  Fold 4, AUC: 0.8059\n",
            "  Fold 5, AUC: 0.8183\n",
            "XGBoost OOF AUC: 0.8095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meta_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayhhjDW5zRhl",
        "outputId": "79ab6073-b6bf-4fce-9579-f5f9d78d69b2"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.38318243e-01, 6.75813024e-01, 9.32537973e-01],\n",
              "       [1.37491267e-01, 1.30641515e-01, 1.99305248e-02],\n",
              "       [3.21204616e-01, 2.54288914e-01, 2.60010272e-01],\n",
              "       ...,\n",
              "       [3.54496373e-02, 2.99904026e-02, 8.83868721e-04],\n",
              "       [1.69734821e-01, 2.23324334e-01, 9.98414755e-02],\n",
              "       [4.87300328e-02, 9.68759429e-02, 3.68798617e-03]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params_logistic = {\n",
        "    \"penalty\": 'l2',             # L2正則化\n",
        "    \"C\": 0.5,                    # 正則化の強さ\n",
        "    \"solver\": 'lbfgs',           # 最適化アルゴリズム\n",
        "    \"max_iter\": 200,             # 最大反復回数\n",
        "    \"class_weight\":'balanced',    # クラスの重みづけ\n",
        "    \"random_state\": 0            # 乱数シード\n",
        "}"
      ],
      "metadata": {
        "id": "RkQvm6CI4IdB"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# メタモデルの定義と学習\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "meta_model = LogisticRegression(**params_logistic)\n",
        "oof_predictions_meta = train_meta_model(meta_features, train_y, meta_model)\n"
      ],
      "metadata": {
        "id": "GO2DZ1ZGj5kc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57cfab1d-d302-495a-b76b-3a29f8b0193e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta Model Fold 1, AUC: 0.8220\n",
            "Meta Model Fold 2, AUC: 0.8449\n",
            "Meta Model Fold 3, AUC: 0.8438\n",
            "Meta Model Fold 4, AUC: 0.8237\n",
            "Meta Model Fold 5, AUC: 0.8515\n",
            "Meta Model OOF AUC: 0.8357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_auc = roc_auc_score(train_y, oof_predictions_meta)\n",
        "print(f\"Final Stacking Model OOF AUC: {final_auc:.8f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euDKcTwdlZ6j",
        "outputId": "33c13f11-52ad-401d-ceab-4a84784fc1c0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Stacking Model OOF AUC: 0.83574240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_models"
      ],
      "metadata": {
        "id": "x4exHIHJ0qCe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c51af54b-076a-4458-c56c-e8ddfb926c50"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LightGBM': LGBMClassifier(colsample_bytree=0.8, learning_rate=0.01, n_estimators=3000,\n",
              "                random_seed=0, subsample=0.8, subsample_freq=1),\n",
              " 'CatBoost': <catboost.core.CatBoostClassifier at 0x7f4843f9c040>,\n",
              " 'XGBoost': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "               colsample_bylevel=None, colsample_bynode=None,\n",
              "               colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
              "               enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "               gamma=None, grow_policy=None, importance_type=None,\n",
              "               interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
              "               max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "               max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "               multi_strategy=None, n_estimators=3000, n_jobs=None,\n",
              "               num_parallel_tree=None, random_state=0, ...)}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_models.values()"
      ],
      "metadata": {
        "id": "QbnB35ov2Agp",
        "outputId": "c4720eb0-bde2-4699-f797-31f54f54c2dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([LGBMClassifier(colsample_bytree=0.8, learning_rate=0.01, n_estimators=3000,\n",
              "               random_seed=0, subsample=0.8, subsample_freq=1), <catboost.core.CatBoostClassifier object at 0x7f4843f9c040>, XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=3000, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=0, ...)])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = stacking_predict(test_x, base_models, meta_model)"
      ],
      "metadata": {
        "id": "T9jDrRKym7Bi"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-XhyoRy0utL",
        "outputId": "0d646349-7c89-41fd-9dd4-498c9b49c3a7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.0801132 , 0.10713224, 0.16697836, ..., 0.69521919, 0.15399334,\n",
              "       0.0541278 ])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions"
      ],
      "metadata": {
        "id": "CFDXAYES9JK1",
        "outputId": "f236caf4-af13-4c7d-cf72-fb0bd26b4f88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.33008663, 0.41308765, 0.55117781, ..., 0.94304322, 0.52771905,\n",
              "       0.23618157])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 2"
      ],
      "metadata": {
        "id": "rAXPuukC9TiL"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "# カウント変数をインクリメント\n",
        "count += 1\n",
        "# 日本時間を取得\n",
        "japan_tz = pytz.timezone('Asia/Tokyo')\n",
        "now = datetime.now(japan_tz)\n",
        "timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "file_name = f\"/content/drive/MyDrive/Signate/2024summer/lightcatxgb_en_{timestamp}_{count:03d}.csv\"\n",
        "ss[1] = test_predictions\n",
        "ss.to_csv(file_name, header=False, index=False)"
      ],
      "metadata": {
        "id": "9sPCTUlG9BNO"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cql4MPkR4e-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pTMlgkLqrNkp"
      }
    }
  ]
}