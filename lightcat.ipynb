{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mamekin05108/signatecup2024summer/blob/main/lightcat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvcbxY4UzTh3",
        "outputId": "bcdb9f35-574d-46db-8e40-1d5f34ba55ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_RmK63MjRXa",
        "outputId": "931510b4-9fef-45d3-87e3-ca0a704ffb63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import re\n",
        "import lightgbm as lgb\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "\n",
        "\n",
        "# warningsを非表示にする\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPtf2SeBzV9X",
        "outputId": "b3fe05c2-2db4-4508-89ce-68a6f5de9af5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"/content/drive/MyDrive/Signate/2024summer/fdata/df_train_allnum.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/Signate/2024summer/fdata/df_test_allnum.csv\")\n",
        "ss = pd.read_csv(\"/content/drive/MyDrive/Signate/2024summer/data/sample_submit.csv\", header=None)"
      ],
      "metadata": {
        "id": "2FTiglD3zYMY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = \"ProdTaken\"\n",
        "\n",
        "\n",
        "cols_category = [\n",
        "    \"Gender\",\n",
        "    \"ProductPitched\",\n",
        "    \"Designation\",\n",
        "    \"MaritalStatus\",\n",
        "    \"OwnCar\",\n",
        "    \"Occupation\",\n",
        "    \"TypeofContact\",\n",
        "    \"Agebin\",\n",
        "    \"Incomebin\",\n",
        "    \"Occupation_Designation\"\n",
        "]\n",
        "\n",
        "\n",
        "cols_category=[]"
      ],
      "metadata": {
        "id": "oX-T1Ta2EtCB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = df_train[target]\n",
        "train_x = df_train.drop(target, axis=1)"
      ],
      "metadata": {
        "id": "jTC1POkYyV0B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = df_test\n",
        "test_x = test_x.drop(target, axis=1)"
      ],
      "metadata": {
        "id": "hljP6qCBzzBU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "DGxFU_lZ_NBs",
        "outputId": "1732b7e1-1ec0-4af1-fa17-c4dcb8f8d58e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id       Age  TypeofContact  DurationOfPitch  Gender  \\\n",
              "0  3489  0.938701              1        -0.212100       0   \n",
              "1  3490 -0.922728              1        -0.356740       1   \n",
              "2  3491 -1.439792              1        -0.790661       1   \n",
              "3  3492 -1.853443              0        -1.079941       0   \n",
              "4  3493  0.214812              0        -1.079941       0   \n",
              "\n",
              "   NumberOfPersonVisiting  NumberOfFollowups  NumberOfTrips  Passport  \\\n",
              "0               -1.908669           0.361786       2.196148         0   \n",
              "1               -1.908669           0.361786       0.459028         1   \n",
              "2               -1.908669           0.361786      -1.278092         0   \n",
              "3               -1.908669           0.361786      -1.278092         0   \n",
              "4               -1.908669           0.361786      -1.278092         0   \n",
              "\n",
              "   MonthlyIncome  ...  PitchSatisfactionScore_5  Designation_AVP  \\\n",
              "0       1.863454  ...                       0.0              1.0   \n",
              "1      -0.742793  ...                       0.0              0.0   \n",
              "2      -1.272115  ...                       0.0              0.0   \n",
              "3      -1.273769  ...                       0.0              0.0   \n",
              "4      -1.155267  ...                       0.0              0.0   \n",
              "\n",
              "   Designation_Executive  Designation_Manager  Designation_Senior Manager  \\\n",
              "0                    0.0                  0.0                         0.0   \n",
              "1                    0.0                  0.0                         1.0   \n",
              "2                    1.0                  0.0                         0.0   \n",
              "3                    0.0                  0.0                         1.0   \n",
              "4                    1.0                  0.0                         0.0   \n",
              "\n",
              "   Designation_VP  MaritalStatus_未婚  MaritalStatus_独身  MaritalStatus_結婚  \\\n",
              "0             0.0               0.0               0.0               1.0   \n",
              "1             0.0               0.0               0.0               1.0   \n",
              "2             0.0               0.0               0.0               0.0   \n",
              "3             0.0               0.0               0.0               0.0   \n",
              "4             0.0               0.0               1.0               0.0   \n",
              "\n",
              "   MaritalStatus_離婚  \n",
              "0               0.0  \n",
              "1               0.0  \n",
              "2               1.0  \n",
              "3               1.0  \n",
              "4               0.0  \n",
              "\n",
              "[5 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d958a09-7d01-4b10-a050-abdbe8033b74\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Age</th>\n",
              "      <th>TypeofContact</th>\n",
              "      <th>DurationOfPitch</th>\n",
              "      <th>Gender</th>\n",
              "      <th>NumberOfPersonVisiting</th>\n",
              "      <th>NumberOfFollowups</th>\n",
              "      <th>NumberOfTrips</th>\n",
              "      <th>Passport</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>...</th>\n",
              "      <th>PitchSatisfactionScore_5</th>\n",
              "      <th>Designation_AVP</th>\n",
              "      <th>Designation_Executive</th>\n",
              "      <th>Designation_Manager</th>\n",
              "      <th>Designation_Senior Manager</th>\n",
              "      <th>Designation_VP</th>\n",
              "      <th>MaritalStatus_未婚</th>\n",
              "      <th>MaritalStatus_独身</th>\n",
              "      <th>MaritalStatus_結婚</th>\n",
              "      <th>MaritalStatus_離婚</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3489</td>\n",
              "      <td>0.938701</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.212100</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.908669</td>\n",
              "      <td>0.361786</td>\n",
              "      <td>2.196148</td>\n",
              "      <td>0</td>\n",
              "      <td>1.863454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3490</td>\n",
              "      <td>-0.922728</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.356740</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.908669</td>\n",
              "      <td>0.361786</td>\n",
              "      <td>0.459028</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.742793</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3491</td>\n",
              "      <td>-1.439792</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.790661</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.908669</td>\n",
              "      <td>0.361786</td>\n",
              "      <td>-1.278092</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.272115</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3492</td>\n",
              "      <td>-1.853443</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.079941</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.908669</td>\n",
              "      <td>0.361786</td>\n",
              "      <td>-1.278092</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.273769</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3493</td>\n",
              "      <td>0.214812</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.079941</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.908669</td>\n",
              "      <td>0.361786</td>\n",
              "      <td>-1.278092</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.155267</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 41 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d958a09-7d01-4b10-a050-abdbe8033b74')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4d958a09-7d01-4b10-a050-abdbe8033b74 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4d958a09-7d01-4b10-a050-abdbe8033b74');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1d81c120-6e7a-4bee-95dd-c943fb8c343b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1d81c120-6e7a-4bee-95dd-c943fb8c343b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1d81c120-6e7a-4bee-95dd-c943fb8c343b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_x"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# モデル\n"
      ],
      "metadata": {
        "id": "jgjYKucvdM4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n"
      ],
      "metadata": {
        "id": "iuqIKz1zDUkh",
        "outputId": "373b9597-b016-43c4-f352-4048d1f710d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.32)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna"
      ],
      "metadata": {
        "id": "50TY5TNODS6B"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OptunaでLightGBMのパラメータをチューニングする関数\n",
        "def objective_lgb(trial, X, y):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 5000),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
        "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
        "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
        "        'random_seed': 0\n",
        "    }\n",
        "\n",
        "    model = lgb.LGBMClassifier(**params)\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=815)\n",
        "    auc_scores = []\n",
        "\n",
        "    for train_idx, val_idx in cv.split(X, y):\n",
        "        trn_x, trn_y = X.iloc[train_idx], y.iloc[train_idx]\n",
        "        val_x, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
        "        model.fit(trn_x, trn_y, eval_set=[(val_x, val_y)], eval_metric='auc', callbacks=[lgb.early_stopping(100, verbose=False)])\n",
        "        preds = model.predict_proba(val_x)[:, 1]\n",
        "        auc_scores.append(roc_auc_score(val_y, preds))\n",
        "\n",
        "    return np.mean(auc_scores)"
      ],
      "metadata": {
        "id": "iFQCp38z3JpH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best LightGBM parameters: {'n_estimators': 3310, 'learning_rate': 0.054222174375827735, 'colsample_bytree': 0.5021459390774948, 'subsample': 0.8448409944410017}"
      ],
      "metadata": {
        "id": "1Ls24OUAJyL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OptunaでCatBoostのパラメータをチューニングする関数\n",
        "def objective_cat(trial, X, y, cols_category):\n",
        "    params = {\n",
        "        'iterations': trial.suggest_int('iterations', 100, 5000),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
        "        'colsample_bylevel': trial.suggest_uniform('colsample_bylevel', 0.5, 1.0),\n",
        "        'random_seed': 0,\n",
        "        'verbose': 100,\n",
        "        'use_best_model': True\n",
        "    }\n",
        "\n",
        "    model = CatBoostClassifier(**params)\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=815)\n",
        "    auc_scores = []\n",
        "\n",
        "    for train_idx, val_idx in cv.split(X, y):\n",
        "        trn_x, trn_y = X.iloc[train_idx], y.iloc[train_idx]\n",
        "        val_x, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
        "        train_pool = Pool(data=trn_x, label=trn_y, cat_features=cols_category)\n",
        "        val_pool = Pool(data=val_x, label=val_y, cat_features=cols_category)\n",
        "        model.fit(train_pool, eval_set=val_pool, verbose=False)\n",
        "        preds = model.predict_proba(val_x)[:, 1]\n",
        "        auc_scores.append(roc_auc_score(val_y, preds))\n",
        "\n",
        "    return np.mean(auc_scores)"
      ],
      "metadata": {
        "id": "QWPGZD9WFfzL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best CatBoost parameters: {'iterations': 2429, 'learning_rate': 0.015201103669488437, 'colsample_bylevel': 0.6320629073348337}"
      ],
      "metadata": {
        "id": "Wz-XbRoiRMM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optunaのスタディを作成し、最適なパラメータを見つける\n",
        "def tune_params(X, y, cols_category):\n",
        "    def opt_lgb(trial):\n",
        "        return objective_lgb(trial, X, y)\n",
        "\n",
        "    def opt_cat(trial):\n",
        "        return objective_cat(trial, X, y, cols_category)\n",
        "\n",
        "    study_lgb = optuna.create_study(direction='maximize')\n",
        "    study_lgb.optimize(opt_lgb, n_trials=50)\n",
        "    print(f\"Best LightGBM parameters: {study_lgb.best_params}\")\n",
        "\n",
        "    study_cat = optuna.create_study(direction='maximize')\n",
        "    study_cat.optimize(opt_cat, n_trials=50)\n",
        "    print(f\"Best CatBoost parameters: {study_cat.best_params}\")\n",
        "\n",
        "    return study_lgb.best_params, study_cat.best_params"
      ],
      "metadata": {
        "id": "dZKvIFwMDK6J"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ベースモデルの学習とメタ特徴量の生成\n",
        "def train_base_models_with_optuna(X, y, cols_category):\n",
        "    best_params_lgb, best_params_cat = tune_params(X, y, cols_category)\n",
        "\n",
        "    print(\"Final LightGBM Parameters:\", best_params_lgb)\n",
        "    print(\"Final CatBoost Parameters:\", best_params_cat)\n",
        "\n",
        "    base_models = {\n",
        "        'LightGBM': lgb.LGBMClassifier(**best_params_lgb),\n",
        "        'CatBoost': CatBoostClassifier(**best_params_cat, early_stopping_rounds=100)\n",
        "    }\n",
        "\n",
        "    meta_features, oof_predictions = train_base_models(X, y, base_models, cols_category)\n",
        "\n",
        "    return base_models, meta_features, oof_predictions"
      ],
      "metadata": {
        "id": "i1YSzCrxN7sM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_base_models(X, y, models, cols_category, n_splits=5):\n",
        "    meta_features = np.zeros((len(X), len(models)))\n",
        "    oof_predictions = np.zeros(len(X))\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=815)\n",
        "\n",
        "    for i, (model_name, model) in enumerate(models.items()):\n",
        "        print(f\"Training {model_name}...\")\n",
        "        oof_predictions_model = np.zeros(len(X))\n",
        "\n",
        "        for fold, (trn_idx, val_idx) in enumerate(cv.split(X, y), start=1):\n",
        "            trn_x, trn_y = X.iloc[trn_idx], y.iloc[trn_idx]\n",
        "            val_x, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "            if isinstance(model, lgb.LGBMClassifier):\n",
        "                model.fit(\n",
        "                    trn_x, trn_y,\n",
        "                    eval_set=[(val_x, val_y)],\n",
        "                    callbacks=[lgb.early_stopping(100, verbose=False)],\n",
        "                    categorical_feature=cols_category,\n",
        "                )\n",
        "            elif isinstance(model, CatBoostClassifier):\n",
        "                train_pool = Pool(data=trn_x, label=trn_y, cat_features=cols_category)\n",
        "                val_pool = Pool(data=val_x, label=val_y, cat_features=cols_category)\n",
        "                model.fit(train_pool, eval_set=val_pool, verbose=False)\n",
        "            else:\n",
        "                model.fit(trn_x, trn_y)\n",
        "\n",
        "            oof_predictions_model[val_idx] = model.predict_proba(val_x)[:, 1]\n",
        "\n",
        "            auc = roc_auc_score(val_y, oof_predictions_model[val_idx])\n",
        "            print(f\"  Fold {fold}, AUC: {auc:.4f}\")\n",
        "\n",
        "        meta_features[:, i] = oof_predictions_model\n",
        "        oof_predictions += oof_predictions_model / len(models)\n",
        "\n",
        "        auc = roc_auc_score(y, oof_predictions_model)\n",
        "        print(f\"{model_name} OOF AUC: {auc:.4f}\")\n",
        "\n",
        "    return meta_features, oof_predictions"
      ],
      "metadata": {
        "id": "aph03ZYAGjTG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_meta_model(meta_features, y, meta_model, n_splits=5):\n",
        "    oof_predictions = np.zeros(len(y))\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=815)\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(cv.split(meta_features, y), start=1):\n",
        "        trn_x, trn_y = meta_features[trn_idx], y.iloc[trn_idx]\n",
        "        val_x, val_y = meta_features[val_idx], y.iloc[val_idx]\n",
        "\n",
        "        meta_model.fit(trn_x, trn_y)\n",
        "        oof_predictions[val_idx] = meta_model.predict_proba(val_x)[:, 1]\n",
        "\n",
        "        auc = roc_auc_score(val_y, oof_predictions[val_idx])\n",
        "        print(f\"Meta Model Fold {fold}, AUC: {auc:.4f}\")\n",
        "\n",
        "    auc = roc_auc_score(y, oof_predictions)\n",
        "    print(f\"Meta Model OOF AUC: {auc:.4f}\")\n",
        "\n",
        "    return oof_predictions"
      ],
      "metadata": {
        "id": "d7hPGtGqnL8i"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stacking_predict(X, base_models, meta_model):\n",
        "    meta_features = np.column_stack([model.predict_proba(X)[:, 1] for _, model in base_models.items()])\n",
        "    return meta_model.predict_proba(meta_features)[:, 1]"
      ],
      "metadata": {
        "id": "NfAqhCaGxfXU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ベースモデルの学習とメタ特徴量の生成\n",
        "base_models, meta_features, oof_predictions_base = train_base_models_with_optuna(train_x, train_y, cols_category)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAdBEO3lxquO",
        "outputId": "6efc52fa-1593-47dd-d68a-4b3af1c9e625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-18 16:21:10,280] A new study created in memory with name: no-name-a330f39c-008d-405d-a899-ffd6ad7ab723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 397, number of negative: 2394\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000567 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142243 -> initscore=-1.796785\n",
            "[LightGBM] [Info] Start training from score -1.796785\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 397, number of negative: 2394\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142243 -> initscore=-1.796785\n",
            "[LightGBM] [Info] Start training from score -1.796785\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 398, number of negative: 2393\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142601 -> initscore=-1.793851\n",
            "[LightGBM] [Info] Start training from score -1.793851\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 398, number of negative: 2393\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000455 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142601 -> initscore=-1.793851\n",
            "[LightGBM] [Info] Start training from score -1.793851\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 398, number of negative: 2394\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000459 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2792, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142550 -> initscore=-1.794269\n",
            "[LightGBM] [Info] Start training from score -1.794269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-18 16:21:12,408] Trial 0 finished with value: 0.8293935495963878 and parameters: {'n_estimators': 4600, 'learning_rate': 0.056908769933251474, 'colsample_bytree': 0.5840907599010865, 'subsample': 0.8437817320143863}. Best is trial 0 with value: 0.8293935495963878.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 397, number of negative: 2394\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000546 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142243 -> initscore=-1.796785\n",
            "[LightGBM] [Info] Start training from score -1.796785\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 397, number of negative: 2394\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142243 -> initscore=-1.796785\n",
            "[LightGBM] [Info] Start training from score -1.796785\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 398, number of negative: 2393\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000485 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142601 -> initscore=-1.793851\n",
            "[LightGBM] [Info] Start training from score -1.793851\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 398, number of negative: 2393\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142601 -> initscore=-1.793851\n",
            "[LightGBM] [Info] Start training from score -1.793851\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 398, number of negative: 2394\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000526 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2792, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142550 -> initscore=-1.794269\n",
            "[LightGBM] [Info] Start training from score -1.794269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-18 16:21:15,906] Trial 1 finished with value: 0.8251752858369684 and parameters: {'n_estimators': 2574, 'learning_rate': 0.004077761250969111, 'colsample_bytree': 0.7152525240096559, 'subsample': 0.7590287547349139}. Best is trial 0 with value: 0.8293935495963878.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 397, number of negative: 2394\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000560 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142243 -> initscore=-1.796785\n",
            "[LightGBM] [Info] Start training from score -1.796785\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 397, number of negative: 2394\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142243 -> initscore=-1.796785\n",
            "[LightGBM] [Info] Start training from score -1.796785\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 398, number of negative: 2393\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142601 -> initscore=-1.793851\n",
            "[LightGBM] [Info] Start training from score -1.793851\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 398, number of negative: 2393\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142601 -> initscore=-1.793851\n",
            "[LightGBM] [Info] Start training from score -1.793851\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 398, number of negative: 2394\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000458 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2792, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142550 -> initscore=-1.794269\n",
            "[LightGBM] [Info] Start training from score -1.794269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-18 16:21:19,064] Trial 2 finished with value: 0.8250694254452329 and parameters: {'n_estimators': 3658, 'learning_rate': 0.0002347975473564264, 'colsample_bytree': 0.6172443565315799, 'subsample': 0.9931899154638488}. Best is trial 0 with value: 0.8293935495963878.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 397, number of negative: 2394\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000557 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142243 -> initscore=-1.796785\n",
            "[LightGBM] [Info] Start training from score -1.796785\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 397, number of negative: 2394\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000540 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142243 -> initscore=-1.796785\n",
            "[LightGBM] [Info] Start training from score -1.796785\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 398, number of negative: 2393\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000515 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142601 -> initscore=-1.793851\n",
            "[LightGBM] [Info] Start training from score -1.793851\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 398, number of negative: 2393\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000552 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142601 -> initscore=-1.793851\n",
            "[LightGBM] [Info] Start training from score -1.793851\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 398, number of negative: 2394\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2792, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142550 -> initscore=-1.794269\n",
            "[LightGBM] [Info] Start training from score -1.794269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-18 16:21:21,803] Trial 3 finished with value: 0.786732338798282 and parameters: {'n_estimators': 4703, 'learning_rate': 0.00020482292419493584, 'colsample_bytree': 0.9960150851867944, 'subsample': 0.6637715445790826}. Best is trial 0 with value: 0.8293935495963878.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 397, number of negative: 2394\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000560 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142243 -> initscore=-1.796785\n",
            "[LightGBM] [Info] Start training from score -1.796785\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 397, number of negative: 2394\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000477 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142243 -> initscore=-1.796785\n",
            "[LightGBM] [Info] Start training from score -1.796785\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 398, number of negative: 2393\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142601 -> initscore=-1.793851\n",
            "[LightGBM] [Info] Start training from score -1.793851\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 398, number of negative: 2393\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2791, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142601 -> initscore=-1.793851\n",
            "[LightGBM] [Info] Start training from score -1.793851\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 398, number of negative: 2394\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000465 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 683\n",
            "[LightGBM] [Info] Number of data points in the train set: 2792, number of used features: 41\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142550 -> initscore=-1.794269\n",
            "[LightGBM] [Info] Start training from score -1.794269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meta_features"
      ],
      "metadata": {
        "id": "ayhhjDW5zRhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_features"
      ],
      "metadata": {
        "id": "0bJ7T3qOAhLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_logistic = {\n",
        "    \"penalty\": 'l2',             # L2正則化\n",
        "    \"C\": 1.0,                    # 正則化の強さ\n",
        "    \"solver\": 'lbfgs',           # 最適化アルゴリズム\n",
        "    \"max_iter\": 100,             # 最大反復回数\n",
        "    #\"class_weight\":'balanced',    # クラスの重みづけ\n",
        "    \"random_state\": 1506            # 乱数シード\n",
        "}"
      ],
      "metadata": {
        "id": "RkQvm6CI4IdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# メタモデルの定義と学習\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "meta_model = LogisticRegression(**params_logistic)\n",
        "oof_predictions_meta = train_meta_model(meta_features, train_y, meta_model)\n"
      ],
      "metadata": {
        "id": "GO2DZ1ZGj5kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Meta Model Fold 1, AUC: 0.8172\n",
        "Meta Model Fold 2, AUC: 0.8446\n",
        "Meta Model Fold 3, AUC: 0.8359\n",
        "Meta Model Fold 4, AUC: 0.8211\n",
        "Meta Model Fold 5, AUC: 0.8641\n",
        "Meta Model OOF AUC: 0.8356"
      ],
      "metadata": {
        "id": "sJvKxJJZAkP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_auc = roc_auc_score(train_y, oof_predictions_meta)\n",
        "print(f\"Final Stacking Model OOF AUC: {final_auc:.8f}\")"
      ],
      "metadata": {
        "id": "euDKcTwdlZ6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = stacking_predict(test_x, oof_predictions_base, meta_model)"
      ],
      "metadata": {
        "id": "T9jDrRKym7Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0"
      ],
      "metadata": {
        "id": "rAXPuukC9TiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "# カウント変数をインクリメント\n",
        "count += 1\n",
        "# 日本時間を取得\n",
        "japan_tz = pytz.timezone('Asia/Tokyo')\n",
        "now = datetime.now(japan_tz)\n",
        "timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "file_name = f\"/content/drive/MyDrive/Signate/2024summer/lightcatxgb_en_{timestamp}_{count:03d}.csv\"\n",
        "ss[1] = test_predictions\n",
        "ss.to_csv(file_name, header=False, index=False)"
      ],
      "metadata": {
        "id": "9sPCTUlG9BNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MloBIyLeAIop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cql4MPkR4e-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pTMlgkLqrNkp"
      }
    }
  ]
}